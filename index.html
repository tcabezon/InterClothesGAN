<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">

    <title>Tcabezon-#FP</title>
    <link rel="shortcut icon" href="firma.png" />
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Mono:wght@100;150;200;250;300;350;400;500;600;900&family=Roboto:wght@100;400;500;900&display=swap');
        @import url('https://fonts.googleapis.com/css2?family=Frank+Ruhl+Libre:wght@300;400;500;700;900&family=Noto+Sans:ital@1&display=swap');

        body {

            margin: 0;
            line-height: normal;
            font-family: 'Noto Sans Mono', monospace;
            letter-spacing: 0px;
            font-weight: 150;

            font-size: 0.9em;
            text-align: justify;
            width: 100%;
        }

        p {
            text-align: justify;
            text-justify: inter-word;
        }

        i {
            font-style: italic;
        }

        b {
            font-weight: 500;
        }

        h2 {
            text-decoration: underline;
        }

        figcaption {
            font-weight: 500;
            text-align: center;
            font-size: 0.8em;
            padding: 8px;
            margin-left: 8px;
        }

        a {
            text-decoration: none;
            color: black;
            font-weight: 350;
            text-decoration: underline;
        }

        a:hover {
            background-color: LavenderBlush;
            color: black;

            font-weight: 500;

            border: none;
        }

        #img_ {
            /* border:1px solid #555; */
            box-shadow: 0 6px 20px 0 rgb(0 0 0 / 19%);
        }

        .iDiv {
            margin: 5%;
        }
    </style>
</head>

<body>
    <div class="content  justify-content-center">

        <div class="container bg-white col-xl-6 col-lg-10 col-md-12">

            <!-- content -->
            <div class='content'>

                <br><br>
                <br><br>
                <br><br>
                <h1 class="text-center"> InterClothesGAN<br>Final Project</h1>

                <br>

                <h6 class="text-center">CMU 16-726 Image Synthesis S22 </h6>
                <h6 class="text-center">Tomas Cabezon Pedroso</h6>


                <br>

                <br><br>



                <div class="container row m-0 p-0 col-12 align-self-center ">
                    <div class="col-lg-3 col-md-2 col-1 align-self-center bg-warning m-0 p-0 "></div>
                    <div class="col-lg-3 col-md-4 col-5 align-self-center bg-warning m-0 p-0 ">
                        <img src="images/interClothGAN/introGIF_s_0.png"
                            class='  d-block float-center mx-auto d-block img-fluid m-0 p-0  col-12'>
                    </div>
                    <div class="col-lg-3 col-md-4 col-5 align-self-center bg-warning m-0 p-0 ">
                        <img src="images/interClothGAN/intro_gif.gif"
                            class='  d-block float-center mx-auto d-block img-fluid m-0 p-0  col-12'>
                    </div>
                </div>
                <br>

                <p>
                    In this project, we will explore the possibilities of interpreting the latent semantics learned by
                    GANs for garment editing. This work is
                    inspired by the paper <a href="https://arxiv.org/pdf/1907.10786.pdf" target="'_blank">'Interpreting
                        the Latent Space of GANs for Semantic Face Editing'</a> and its final objective is to find other
                    domains in which to apply this study.
                    The project is divided into two
                    parts: the first part, consists on the trainning of a StyleGAN on the Viton dataset for its
                    posterior analysis. In the second part, we will conduct a study of the diferent features encoded in
                    the learned latent space to control of different garment features, such as, sleeve length or
                    texture.
                </p>
                <br><br><br>
                <h2>InterFaceGAN</h2>
                <br><br>
                <h4>Interpreting latent space</h4>
                <br>
                <p>
                    In the <a href="https://arxiv.org/pdf/1907.10786.pdf" target="'_blank">InterFaceGAN</a> paper, the
                    authors show how they found that:

                <div class="iDiv">
                    <i>
                        "the latent code of <b>well-trained generative
                            models actually learns a disentangled representation after linear transformations.</b> We
                        explore
                        the disentanglement between various semantics and manage to decouple some entangled semantics
                        with subspace projection, leading to more precise control of facial attributes."
                    </i>
                </div>


                This project is based on the exploration of the possibilities of this latent space exploration in
                other domains, as it could be fashion, and garment tweaking. To do so, we have followed the claim of
                the previous paper:

                <div class="iDiv">
                    <i>
                        "It has been widely observed that when linearly interpolating two latent codes z1 and z2, the
                        appearance of the corresponding synthesis changes continuously.<br><br>
                        According to Property 1, the linear interpolation between z1 and z2 forms a direction in Z,
                        which
                        further defines a hyperplane. We therefore make an assumption that for any binary semantic,
                        <b>there exists a hyperplane in the latent space serving as the separation boundary.</b>
                        Semantic remains the same when the latent code walks within the same side of the hyperplane yet
                        turns into the opposite when across the boundary"
                    </i>
                </div>

                To find this boundary, a vector-support machine (SVM) is used. Points belonging to the extremes of each
                binary feature are used to find the hyperplane as it can be seen in the following image.

                </p>
                <br>
                <img src="images/interClothGAN/svm.png" class='  d-block float-center mx-auto d-block img-fluid col-6'>
                <figcaption class='  d-block float-center mx-auto d-block img-fluid col-6'>Diagram of an SVM finding the hyperplane that separates two different classes of data points.</figcaption>
                <br>
                <br>

                <h2>StyleGAN</h2>

                <br>
                <p>
                    In this firt part, a StyleGAN is trained to later perform the latent space study. <a
                        href="https://github.com/NVlabs/stylegan" target="'_blank">Nvidia's StyleGan</a> is used to
                    train this GAN on the <a href="https://www.kaggle.com/datasets/rkuo2000/viton-dataset"
                        target="'_blank">Viton dataset</a>, composed of is used
                    14.221 images of different top garments.

                </p>
                <br>
                <img src="images/interClothGAN/train_gif.gif"
                    class='  d-block float-center mx-auto d-block img-fluid col-12'>
                <figcaption>Training process of the styleGAN.</figcaption>
                <br><br>
                <p>
                    In the following images the losses of the training of our model can be seen. We kept track of the
                    FID50k score during training, receiving a final score of 26.11. The scores given by the
                    discriminator to the real images, as well as, the scores of fake images get closer to the absolute
                    value of 0.5, showing that during training the model improves.
                </p>
                <br>
                <br>
                <br>
                <img src="images/interClothGAN/training_losses.png"
                    class='  d-block float-center mx-auto d-block img-fluid col-10'>
                <br>
                <figcaption>FID50K Scores of the StyleGAN training.</figcaption>

                <br>
                <br>
                <br>
                <div class="container row m-0 p-0 col-12 align-self-center ">
                    <div class="col-1 align-self-center  m-0 p-0 "></div>
                    <div class="col-5 align-self-center  m-0 p-0 ">
                        <img src="images/interClothGAN/real_losses.png"
                            class='  d-block float-center mx-auto d-block img-fluid m-0 p-0  col-12'>
                        <figcaption><br>Loss/scores of real images.</figcaption>

                    </div>
                    <div class="col-5 align-self-center  m-0 p-0 ">
                        <img src="images/interClothGAN/fake_losses.png"
                            class='  d-block float-center mx-auto d-block img-fluid m-0 p-0  col-12'>
                        <figcaption><br>Loss/scores of fake images.</figcaption>
                    </div>
                </div>

                <br><br><br>

                <h2>Boundaries</h2>

                <br><br>
                <p>

                    Once we have a well trained GAN we procede to explore the disentaglement of the different
                    features. We used the previously explained SVM to find the hyperplanes that separete the boundaries
                    and get the normal vectors to this hyperplanes as the feature editing directions.
                    To manipulate/tweak any attribute, we edit the
                    original latent code <b><i>z</i></b> as:
                    <br><br>
                    <img class="d-block float-center mx-auto d-block img-fluid col-5 col-md-3 col-lg-2"
                        id="equationview" name="equationview"
                        src="https://latex.codecogs.com/svg.image?z_{edit}=z&plus;\alpha&space;n">
                    <br>
                    where <b><i>α</i></b> is the parameter that shifts <b><i>z</i></b> on the editing direction
                    <b><i>n</i></b>, which the unit vector normal to the boundary hyperplane. In the following
                    image is a diagram of how the sleeve length editing direction was found. Apart from this feature, we
                    also found the direction to edit the texture of the garment as well as the redness of it.
                </p>
                <br>
                <img src="images/interClothGAN/boundary.jpg"
                    class='  d-block float-center mx-auto d-block img-fluid col-11'>
                <figcaption class="col-7 d-block float-center mx-auto d-block "><br>Examples used to find the <i>sleeve
                        length</i> boundary in the latent space.</figcaption>

                <br><br><br>

                <h2>Results</h2>

                <br><br>
                <p>

                    A garment generated by the StyleGAN generator can be tweaked using the
                    found editing directions allowing the user to explore the design space.
                </p>
                <br>
                <img src="images/interClothGAN/SLIDERS.jpg"
                    class='  d-block float-center mx-auto d-block img-fluid col-10'>
                <figcaption class="col-10 d-block float-center mx-auto d-block "><br>On the left, original image without
                    editing. The columns to the right, corresponding results after applying the changes.</figcaption>
                <br><br><br>

                <h2>Demo</h2>

                <br><br>
                <p>

                    Bellow, a demo of the possible interaction between the user and the proposed InterClothGAN is shown.
                </p>
                <br>
                <img id='img_' src="images/interClothGAN/demo_gifHQ.gif"
                    class='  d-block float-center mx-auto d-block img-fluid col-12'>
                <figcaption class="col-7 d-block float-center mx-auto d-block "><br>Demo of the InterClothesGAN.
                </figcaption>

                <br>
















                <br><br><br><br>
                <p class=footer>©Tomas Cabezon Pedroso, 2021</p>



            </div> <!-- end content -->
        </div>
</body>

</html>